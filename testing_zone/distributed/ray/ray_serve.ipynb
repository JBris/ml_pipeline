{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c5a918",
   "metadata": {},
   "source": [
    "Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70becf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:30:49,369\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      " pid=10520)\u001b[0m 2021-12-05 19:30:57,607\tINFO checkpoint_path.py:16 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      " pid=10520)\u001b[0m 2021-12-05 19:30:57,614\tINFO http_state.py:98 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:gxNELu:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n",
      "2021-12-05 19:30:58,352\tINFO api.py:463 -- Started Serve instance in namespace 'serve'.\n",
      " pid=6660)\u001b[0m INFO:     Started server process [6660]\n",
      "2021-12-05 19:30:58,470\tINFO api.py:242 -- Updating deployment 'hello'. component=serve deployment=hello\n",
      " pid=10520)\u001b[0m 2021-12-05 19:30:58,487\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'hello'. component=serve deployment=hello\n",
      "2021-12-05 19:30:59,297\tINFO api.py:249 -- Deployment 'hello' is ready at `http://127.0.0.1:8000/hello`. component=serve deployment=hello\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from ray import serve\n",
    "\n",
    "serve.start()\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "def hello(request):\n",
    "    name = request.query_params[\"name\"]\n",
    "    return f\"Hello {name}!\"\n",
    "\n",
    "\n",
    "hello.deploy()\n",
    "\n",
    "# Query our endpoint over HTTP.\n",
    "response = requests.get(\"http://127.0.0.1:8000/hello?name=serve\").text\n",
    "assert response == \"Hello serve!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "serve.start()\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        self.count += 1\n",
    "        return {\"count\": self.count}\n",
    "\n",
    "\n",
    "# Deploy our class.\n",
    "Counter.deploy()\n",
    "\n",
    "# Query our endpoint in two different ways: from HTTP and from Python.\n",
    "assert requests.get(\"http://127.0.0.1:8000/Counter\").json() == {\"count\": 1}\n",
    "assert ray.get(Counter.get_handle().remote()) == {\"count\": 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7bbb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 3}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ray.get(Counter.get_handle().remote())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3a1652",
   "metadata": {},
   "source": [
    "End-to-End Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70690912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:38:13,013\tINFO worker.py:852 -- Calling ray.init() again after it has already been called.\n",
      "2021-12-05 18:38:13,014\tINFO api.py:414 -- Connecting to existing Serve instance in namespace 'serve'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.serve.api.Client at 0x15df2297c40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "serve.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af79bc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:38:43,460\tINFO api.py:242 -- Updating deployment 'Counter'. component=serve deployment=Counter\n",
      " pid=10144)\u001b[0m 2021-12-05 18:38:43,559\tINFO deployment_state.py:874 -- Stopping 1 replicas of deployment 'Counter' with outdated versions. component=serve deployment=Counter\n",
      " pid=10144)\u001b[0m 2021-12-05 18:38:45,728\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'Counter'. component=serve deployment=Counter\n",
      "2021-12-05 18:38:49,355\tINFO api.py:249 -- Deployment 'Counter' is ready at `http://127.0.0.1:8000/Counter`. component=serve deployment=Counter\n"
     ]
    }
   ],
   "source": [
    "@serve.deployment\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    def __call__(self, request):\n",
    "        self.count += 1\n",
    "        return {\"count\": self.count}\n",
    "Counter.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "031ec38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:41:14,070\tINFO api.py:242 -- Updating deployment 'Counter'. component=serve deployment=Counter\n",
      " pid=10144)\u001b[0m 2021-12-05 18:41:14,187\tINFO deployment_state.py:874 -- Stopping 1 replicas of deployment 'Counter' with outdated versions. component=serve deployment=Counter\n",
      " pid=10144)\u001b[0m 2021-12-05 18:41:16,404\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'Counter'. component=serve deployment=Counter\n",
      "2021-12-05 18:41:19,243\tINFO api.py:249 -- Deployment 'Counter' is ready at `http://127.0.0.1:8000/Counter`. component=serve deployment=Counter\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@serve.deployment\n",
    "@serve.ingress(app)\n",
    "class Counter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    @app.get(\"/\")\n",
    "    def get(self):\n",
    "        return {\"count\": self.count}\n",
    "\n",
    "    @app.get(\"/incr\")\n",
    "    def incr(self):\n",
    "        self.count += 1\n",
    "        return {\"count\": self.count}\n",
    "\n",
    "    @app.get(\"/decr\")\n",
    "    def decr(self):\n",
    "        self.count -= 1\n",
    "        return {\"count\": self.count}\n",
    "Counter.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8663f6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"count\":0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    11  100    11    0     0     50      0 --:--:-- --:--:-- --:--:--    50\n"
     ]
    }
   ],
   "source": [
    "! curl -X GET localhost:8000/Counter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ab04bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"count\":1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0    11    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    11  100    11    0     0     50      0 --:--:-- --:--:-- --:--:--    50\n"
     ]
    }
   ],
   "source": [
    "! curl -X GET localhost:8000/Counter/incr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d81ed02",
   "metadata": {},
   "source": [
    "Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1209430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:45:15,669\tINFO api.py:242 -- Updating deployment 'MyFirstDeployment'. component=serve deployment=MyFirstDeployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:45:15,734\tINFO deployment_state.py:874 -- Stopping 1 replicas of deployment 'MyFirstDeployment' with outdated versions. component=serve deployment=MyFirstDeployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:45:17,945\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'MyFirstDeployment'. component=serve deployment=MyFirstDeployment\n",
      "2021-12-05 18:45:20,482\tINFO api.py:249 -- Deployment 'MyFirstDeployment' is ready at `http://127.0.0.1:8000/MyFirstDeployment`. component=serve deployment=MyFirstDeployment\n"
     ]
    }
   ],
   "source": [
    "@serve.deployment\n",
    "class MyFirstDeployment:\n",
    "  # Take the message to return as an argument to the constructor.\n",
    "    def __init__(self, msg):\n",
    "        self.msg = msg\n",
    "        \n",
    "    def __call__(self, request):\n",
    "        return self.msg\n",
    "\n",
    "    def other_method(self, arg):\n",
    "        return self.msg\n",
    "\n",
    "MyFirstDeployment.deploy(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cef5be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:45:53,411\tINFO api.py:242 -- Updating deployment 'hello_service'. component=serve deployment=hello_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:45:53,512\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'hello_service'. component=serve deployment=hello_service\n",
      "2021-12-05 18:45:56,369\tINFO api.py:249 -- Deployment 'hello_service' is ready at `http://127.0.0.1:8000/hello_service`. component=serve deployment=hello_service\n",
      "2021-12-05 18:45:56,379\tINFO api.py:242 -- Updating deployment 'hi_service'. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:45:56,478\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'hi_service'. component=serve deployment=hi_service\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14280/811354324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mMyFirstDeployment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hello_service\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mMyFirstDeployment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"hi_service\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hi!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mdeploy\u001b[1;34m(self, _blocking, *init_args, **init_kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0minit_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         return _get_global_client().deploy(\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_or_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRayServeException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Client has already been shut down.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mdeploy\u001b[1;34m(self, name, deployment_def, init_args, init_kwargs, ray_actor_options, config, version, prev_version, route_prefix, url, _blocking)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_blocking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_goal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoal_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m             logger.info(\n\u001b[0;32m    250\u001b[0m                 \u001b[1;34mf\"Deployment '{name}{':'+version if version else ''}' is ready\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36m_wait_for_goal\u001b[1;34m(self, goal_id, timeout)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         ready, _ = ray.wait(\n\u001b[0m\u001b[0;32m    178\u001b[0m             [self._controller.wait_for_goal.remote(goal_id)], timeout=timeout)\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# AsyncGoal could return exception if set, ray.get()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"init\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[0;32m   1887\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MyFirstDeployment.options(name=\"hello_service\").deploy(\"Hello!\")\n",
    "MyFirstDeployment.options(name=\"hi_service\").deploy(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5af198e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "serve.list_deployments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18adc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(ServeController\r",
      " pid=10144)\u001b[0m 2021-12-05 18:46:56,798\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\r\n"
     ]
    }
   ],
   "source": [
    "deployment = serve.get_deployment(\"MyFirstDeployment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28891e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:47:31,436\tINFO api.py:242 -- Updating deployment 'http_deployment'. component=serve deployment=http_deployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:47:31,483\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'http_deployment'. component=serve deployment=http_deployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:47:56,916\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:48:01,576\tWARNING deployment_state.py:1109 -- Deployment 'http_deployment' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=http_deployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:48:26,944\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:48:31,622\tWARNING deployment_state.py:1109 -- Deployment 'http_deployment' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=http_deployment\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14280/3902536723.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"Hello world!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mHTTPDeployment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hello world!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://127.0.0.1:8000/api\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mdeploy\u001b[1;34m(self, _blocking, *init_args, **init_kwargs)\u001b[0m\n\u001b[0;32m    787\u001b[0m             \u001b[0minit_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m         return _get_global_client().deploy(\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func_or_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRayServeException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Client has already been shut down.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36mdeploy\u001b[1;34m(self, name, deployment_def, init_args, init_kwargs, ray_actor_options, config, version, prev_version, route_prefix, url, _blocking)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_blocking\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_goal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoal_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m             logger.info(\n\u001b[0;32m    250\u001b[0m                 \u001b[1;34mf\"Deployment '{name}{':'+version if version else ''}' is ready\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\serve\\api.py\u001b[0m in \u001b[0;36m_wait_for_goal\u001b[1;34m(self, goal_id, timeout)\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m         ready, _ = ray.wait(\n\u001b[0m\u001b[0;32m    178\u001b[0m             [self._controller.wait_for_goal.remote(goal_id)], timeout=timeout)\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# AsyncGoal could return exception if set, ray.get()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"init\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\envs\\yourenvname\\lib\\site-packages\\ray\\worker.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_refs, num_returns, timeout, fetch_local)\u001b[0m\n\u001b[0;32m   1884\u001b[0m         \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m         \u001b[0mtimeout_milliseconds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1886\u001b[1;33m         ready_ids, remaining_ids = worker.core_worker.wait(\n\u001b[0m\u001b[0;32m   1887\u001b[0m             \u001b[0mobject_refs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1888\u001b[0m             \u001b[0mnum_returns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.CoreWorker.wait\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpython\\ray\\_raylet.pyx\u001b[0m in \u001b[0;36mray._raylet.check_status\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@serve.deployment(name=\"http_deployment\", route_prefix=\"/api\")\n",
    "class HTTPDeployment:\n",
    "    def __call__(self, request):\n",
    "        return \"Hello world!\"\n",
    "import requests\n",
    "HTTPDeployment.deploy(\"Hello world!\")\n",
    "print(requests.get(\"http://127.0.0.1:8000/api\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd9476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 18:48:38,523\tWARNING api.py:308 -- You are retrieving a sync handle inside an asyncio loop. Try getting client.get_handle(.., sync=False) to get better performance. Learn more at https://docs.ray.io/en/master/serve/http-servehandle.html#sync-and-async-handles\n",
      " pid=10144)\u001b[0m 2021-12-05 18:48:56,970\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:49:01,715\tWARNING deployment_state.py:1109 -- Deployment 'http_deployment' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=http_deployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:49:27,100\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:49:31,723\tWARNING deployment_state.py:1109 -- Deployment 'http_deployment' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=http_deployment\n",
      " pid=10144)\u001b[0m 2021-12-05 18:49:57,580\tWARNING deployment_state.py:1109 -- Deployment 'hi_service' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=hi_service\n",
      " pid=10144)\u001b[0m 2021-12-05 18:50:01,787\tWARNING deployment_state.py:1109 -- Deployment 'http_deployment' has 1 replicas that have taken more than 30s to be scheduled. This may be caused by waiting for the cluster to auto-scale, or waiting for a runtime environment to install. Resources required for each replica: {'CPU': 1}, resources available: {}. component=serve deployment=http_deployment\n"
     ]
    }
   ],
   "source": [
    "# To get a handle from the same script, use the Deployment object directly:\n",
    "handle = HTTPDeployment.get_handle()\n",
    "\n",
    "# To get a handle from a different script, reference it by name:\n",
    "handle = serve.get_deployment(\"http_deployment\").get_handle()\n",
    "\n",
    "print(ray.get(handle.remote()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2200ce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(name=\"my_deployment\", num_replicas=1)\n",
    "class SimpleDeployment:\n",
    "    pass\n",
    "\n",
    "# Creates one initial replica.\n",
    "SimpleDeployment.deploy()\n",
    "\n",
    "# Re-deploys, creating an additional replica.\n",
    "# This could be the SAME Python script, modified and re-run.\n",
    "@serve.deployment(name=\"my_deployment\", num_replicas=2)\n",
    "class SimpleDeployment:\n",
    "    pass\n",
    "\n",
    "SimpleDeployment.deploy()\n",
    "\n",
    "# You can also use Deployment.options() to change options without redefining\n",
    "# the class. This is useful for programmatically updating deployments.\n",
    "SimpleDeployment.options(num_replicas=2).deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af1f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    _autoscaling_config={\n",
    "        \"min_replicas\": 1,\n",
    "        \"max_replicas\": 5,\n",
    "        \"target_num_ongoing_requests_per_replica\": 10,\n",
    "    },\n",
    "    version=\"v1\")\n",
    "def func(_):\n",
    "    time.sleep(1)\n",
    "    return \"\"\n",
    "\n",
    "func.deploy() # The func deployment will now autoscale based on requests demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "@serve.deployment(\n",
    "    _autoscaling_config={\n",
    "        \"min_replicas\": 1,\n",
    "        \"max_replicas\": 5,\n",
    "        \"target_num_ongoing_requests_per_replica\": 10,\n",
    "    },\n",
    "    version=\"v1\")\n",
    "def func(_):\n",
    "    time.sleep(1)\n",
    "    return \"\"\n",
    "\n",
    "func.deploy() # The func deployment will now autoscale based on requests demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba205c6d",
   "metadata": {},
   "source": [
    "FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b26e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from ray import serve\n",
    "\n",
    "app = FastAPI()\n",
    "ray.init(address=\"auto\", namespace=\"summarizer\")\n",
    "serve.start(detached=True)\n",
    "\n",
    "@serve.deployment(route_prefix=\"/hello\")\n",
    "@serve.ingress(app)\n",
    "class MyFastAPIDeployment:\n",
    "    @app.get(\"/\")\n",
    "    def root(self):\n",
    "        return \"Hello, world!\"\n",
    "\n",
    "    @app.post(\"/{subpath}\")\n",
    "    def root(self, subpath: str):\n",
    "        return f\"Hello from {subpath}!\"\n",
    "\n",
    "MyFastAPIDeployment.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da542891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from ray import serve\n",
    "from starlette.middleware import Middleware\n",
    "from starlette.middleware.cors import CORSMiddleware\n",
    "\n",
    "app = FastAPI()\n",
    "ray.init(address=\"auto\", namespace=\"summarizer\")\n",
    "\n",
    "client = serve.start(\n",
    "    detached=True,\n",
    "    http_options={\"middlewares\": [\n",
    "        Middleware(\n",
    "            CORSMiddleware, allow_origins=[\"*\"], allow_methods=[\"*\"])\n",
    "    ]})\n",
    "\n",
    "@app.get(\"/\")\n",
    "def f():\n",
    "    return \"Hello from the root!\"\n",
    "\n",
    "@serve.deployment(route_prefix=\"/api1\")\n",
    "@serve.ingress(app)\n",
    "class FastAPIWrapper1:\n",
    "    @app.get(\"/subpath\")\n",
    "    def method(self):\n",
    "        return \"Hello 1!\"\n",
    "\n",
    "@serve.deployment(route_prefix=\"/api2\")\n",
    "@serve.ingress(app)\n",
    "class FastAPIWrapper2:\n",
    "    @app.get(\"/subpath\")\n",
    "    def method(self):\n",
    "        return \"Hello 2!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5a9df",
   "metadata": {},
   "source": [
    "Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "import time\n",
    "\n",
    "# This will start Ray locally and start Serve on top of it.\n",
    "serve.start()\n",
    "\n",
    "@serve.deployment\n",
    "def my_func(request):\n",
    "    return \"hello\"\n",
    "\n",
    "my_func.deploy()\n",
    "\n",
    "# Serve will be shut down once the script exits, so keep it alive manually.\n",
    "while True:\n",
    "    time.sleep(5)\n",
    "    print(serve.list_deployments())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2b15ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "# This will connect to the running Ray cluster.\n",
    "ray.init(address=\"auto\", namespace=\"serve\")\n",
    "\n",
    "@serve.deployment\n",
    "def my_func(request):\n",
    "    return \"hello\"\n",
    "\n",
    "my_func.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0e20b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:34:11,241\tINFO api.py:242 -- Updating deployment 'f'. component=serve deployment=f\n",
      " pid=9644)\u001b[0m 2021-12-05 19:34:11,299\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'f'. component=serve deployment=f\n",
      "2021-12-05 19:34:12,327\tINFO api.py:249 -- Deployment 'f' is ready at `http://127.0.0.1:8000/f`. component=serve deployment=f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [404]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from ray import serve\n",
    "import requests\n",
    "\n",
    "#serve.start()\n",
    "\n",
    "logger = logging.getLogger(\"ray\")\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "def f(*_args):\n",
    "    logger.info(\"Some info!\")\n",
    "\n",
    "\n",
    "f.deploy()\n",
    "\n",
    "requests.get(\"http://127.0.0.1:8000/Counter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26aa71a",
   "metadata": {},
   "source": [
    "Serving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb19efb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:34:15,580\tINFO api.py:242 -- Updating deployment 'BatchingExample'. component=serve deployment=BatchingExample\n",
      " pid=9644)\u001b[0m 2021-12-05 19:34:15,616\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'BatchingExample'. component=serve deployment=BatchingExample\n",
      "2021-12-05 19:34:18,496\tINFO api.py:249 -- Deployment 'BatchingExample' is ready at `http://127.0.0.1:8000/increment`. component=serve deployment=BatchingExample\n"
     ]
    }
   ],
   "source": [
    "@serve.deployment(route_prefix=\"/increment\")\n",
    "class BatchingExample:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "\n",
    "    @serve.batch\n",
    "    async def handle_batch(self, requests):\n",
    "        responses = []\n",
    "        for request in requests:\n",
    "            responses.append(request.json())\n",
    "\n",
    "        return responses\n",
    "\n",
    "    async def __call__(self, request):\n",
    "        return await self.handle_batch(request)\n",
    "\n",
    "BatchingExample.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eb7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 19:34:36,534\tINFO api.py:242 -- Updating deployment 'model_one'. component=serve deployment=model_one\n",
      " pid=9644)\u001b[0m 2021-12-05 19:34:36,543\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'model_one'. component=serve deployment=model_one\n",
      "2021-12-05 19:34:39,377\tINFO api.py:249 -- Deployment 'model_one' is ready at `http://127.0.0.1:8000/model_one`. component=serve deployment=model_one\n",
      "2021-12-05 19:34:39,391\tINFO api.py:242 -- Updating deployment 'model_two'. component=serve deployment=model_two\n",
      " pid=9644)\u001b[0m 2021-12-05 19:34:39,493\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'model_two'. component=serve deployment=model_two\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "import requests\n",
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "#ray.init(num_cpus=8)\n",
    "#serve.start()\n",
    "\n",
    "# Our pipeline will be structured as follows:\n",
    "# - Input comes in, the composed model sends it to model_one\n",
    "# - model_one outputs a random number between 0 and 1, if the value is\n",
    "#   greater than 0.5, then the data is sent to model_two\n",
    "# - otherwise, the data is returned to the user.\n",
    "\n",
    "# Let's define two models that just print out the data they received.\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "def model_one(data):\n",
    "    print(\"Model 1 called with data \", data)\n",
    "    return random()\n",
    "\n",
    "\n",
    "model_one.deploy()\n",
    "\n",
    "\n",
    "@serve.deployment\n",
    "def model_two(data):\n",
    "    print(\"Model 2 called with data \", data)\n",
    "    return data\n",
    "\n",
    "\n",
    "model_two.deploy()\n",
    "\n",
    "\n",
    "# max_concurrent_queries is optional. By default, if you pass in an async\n",
    "# function, Ray Serve sets the limit to a high number.\n",
    "@serve.deployment(max_concurrent_queries=10, route_prefix=\"/composed\")\n",
    "class ComposedModel:\n",
    "    def __init__(self):\n",
    "        self.model_one = model_one.get_handle()\n",
    "        self.model_two = model_two.get_handle()\n",
    "\n",
    "    # This method can be called concurrently!\n",
    "    async def __call__(self, starlette_request):\n",
    "        data = await starlette_request.body()\n",
    "\n",
    "        score = await self.model_one.remote(data=data)\n",
    "        if score > 0.5:\n",
    "            result = await self.model_two.remote(data=data)\n",
    "            result = {\"model_used\": 2, \"score\": score}\n",
    "        else:\n",
    "            result = {\"model_used\": 1, \"score\": score}\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "ComposedModel.deploy()\n",
    "\n",
    "for _ in range(5):\n",
    "    resp = requests.get(\"http://127.0.0.1:8000/composed\", data=\"hey!\")\n",
    "    print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4037cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow.pyfunc\n",
    "\n",
    "@serve.deployment\n",
    "class MLflowDeployment:\n",
    "    def __init__(self, model_uri):\n",
    "        self.model = mlflow.pyfunc.load_model(model_uri=model_uri)\n",
    "\n",
    "    async def __call__(self, request):\n",
    "        csv_text = await request.body() # The body contains just raw csv text.\n",
    "        df = pd.read_csv(csv_text)\n",
    "        return self.model.predict(df)\n",
    "\n",
    "model_uri = \"model:/my_registered_model/Production\"\n",
    "MLflowDeployment.deploy(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a393c1",
   "metadata": {},
   "source": [
    "Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe420f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.46\n"
     ]
    }
   ],
   "source": [
    "from ray import serve\n",
    "\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load data\n",
    "iris_dataset = load_iris()\n",
    "data, target, target_names = iris_dataset[\"data\"], iris_dataset[\n",
    "    \"target\"], iris_dataset[\"target_names\"]\n",
    "\n",
    "# Instantiate model\n",
    "model = GradientBoostingClassifier()\n",
    "\n",
    "# Training and validation split\n",
    "np.random.shuffle(data), np.random.shuffle(target)\n",
    "train_x, train_y = data[:100], target[:100]\n",
    "val_x, val_y = data[100:], target[100:]\n",
    "\n",
    "# Train and evaluate models\n",
    "model.fit(train_x, train_y)\n",
    "print(\"MSE:\", mean_squared_error(model.predict(val_x), val_y))\n",
    "\n",
    "# Save the model and label to file\n",
    "MODEL_PATH = os.path.join(tempfile.gettempdir(),\n",
    "                          \"iris_model_logistic_regression.pkl\")\n",
    "LABEL_PATH = os.path.join(tempfile.gettempdir(), \"iris_labels.json\")\n",
    "\n",
    "with open(MODEL_PATH, \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "with open(LABEL_PATH, \"w\") as f:\n",
    "    json.dump(target_names.tolist(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05c2e935",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=9644)\u001b[0m 2021-12-05 19:33:33,733\tINFO checkpoint_path.py:16 -- Using RayInternalKVStore for controller checkpoint and recovery.\n",
      " pid=9644)\u001b[0m 2021-12-05 19:33:33,742\tINFO http_state.py:98 -- Starting HTTP proxy with name 'SERVE_CONTROLLER_ACTOR:SERVE_PROXY_ACTOR-node:127.0.0.1-0' on node 'node:127.0.0.1-0' listening on '127.0.0.1:8000'\n",
      "2021-12-05 19:33:34,643\tINFO api.py:463 -- Started detached Serve instance in namespace 'serve'.\n",
      "2021-12-05 19:33:34,664\tINFO api.py:242 -- Updating deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      " pid=8392)\u001b[0m INFO:     Started server process [8392]\n",
      " pid=9644)\u001b[0m 2021-12-05 19:33:34,710\tINFO deployment_state.py:912 -- Adding 1 replicas to deployment 'BoostingModel'. component=serve deployment=BoostingModel\n",
      "2021-12-05 19:33:37,373\tINFO api.py:249 -- Deployment 'BoostingModel' is ready at `http://127.0.0.1:8000/regressor`. component=serve deployment=BoostingModel\n"
     ]
    }
   ],
   "source": [
    "@serve.deployment(route_prefix=\"/regressor\")\n",
    "class BoostingModel:\n",
    "    def __init__(self):\n",
    "        with open(MODEL_PATH, \"rb\") as f:\n",
    "            self.model = pickle.load(f)\n",
    "        with open(LABEL_PATH) as f:\n",
    "            self.label_list = json.load(f)\n",
    "\n",
    "    async def __call__(self, starlette_request):\n",
    "        payload = await starlette_request.json()\n",
    "        print(\"Worker: received starlette request with data\", payload)\n",
    "\n",
    "        input_vector = [\n",
    "            payload[\"sepal length\"],\n",
    "            payload[\"sepal width\"],\n",
    "            payload[\"petal length\"],\n",
    "            payload[\"petal width\"],\n",
    "        ]\n",
    "        prediction = self.model.predict([input_vector])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name}\n",
    "\n",
    "serve.start(detached=True)\n",
    "BoostingModel.deploy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5abc6b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"result\": \"virginica\"\n",
      "}\n",
      " pid=3844)\u001b[0m Worker: received starlette request with data {'sepal length': 1.2, 'sepal width': 1.0, 'petal length': 1.1, 'petal width': 0.9}\n"
     ]
    }
   ],
   "source": [
    "sample_request_input = {\n",
    "    \"sepal length\": 1.2,\n",
    "    \"sepal width\": 1.0,\n",
    "    \"petal length\": 1.1,\n",
    "    \"petal width\": 0.9,\n",
    "}\n",
    "response = requests.get(\n",
    "    \"http://localhost:8000/regressor\", json=sample_request_input)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
