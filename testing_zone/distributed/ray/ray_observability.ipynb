{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa00a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:01:23,427\tINFO worker.py:842 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Alive': True,\n",
      "  'MetricsExportPort': 62807,\n",
      "  'NodeID': 'e26fe98a02765160d541d61f013d630d4235438b4ad23ee2b146dbd2',\n",
      "  'NodeManagerAddress': '127.0.0.1',\n",
      "  'NodeManagerHostname': 'LAPTOP-5F3V9FNM',\n",
      "  'NodeManagerPort': 61450,\n",
      "  'ObjectManagerPort': 61448,\n",
      "  'ObjectStoreSocketName': 'tcp://127.0.0.1:64348',\n",
      "  'RayletSocketName': 'tcp://127.0.0.1:64500',\n",
      "  'Resources': {'CPU': 4.0,\n",
      "                'GPU': 1.0,\n",
      "                'memory': 1592052942.0,\n",
      "                'node:127.0.0.1': 1.0,\n",
      "                'object_store_memory': 796026470.0},\n",
      "  'alive': True}]\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init(address='auto')\n",
    "from pprint import pprint\n",
    "pprint(ray.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a206aa92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:02:32,408\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting actor.\n",
      "Calling actor.\n",
      "Calling actor.\n",
      "Metrics should be exported.\n",
      "See http://localhost:8080 (this may take a few seconds to load).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:02:53,803\tWARNING worker.py:1245 -- The actor or task with ID ffffffffffffffffd7edaf1ddecbbf7e698644fb01000000 cannot be scheduled right now. You can ignore this message if this Ray cluster is expected to auto-scale or if you specified a runtime_env for this actor or task, which may take time to install.  Otherwise, this is likely due to all cluster resources being claimed by actors. To resolve the issue, consider creating fewer actors or increasing the resources available to this Ray cluster.\n",
      "Required resources for this actor or task: {GPU: 1.000000}, {CPU: 1.000000}\n",
      "Available resources on this node: {3.000000/4.000000 CPU, 48934800.000000 GiB/48934800.000000 GiB memory, 0.000000/1.000000 GPU, 24467400.000000 GiB/24467400.000000 GiB object_store_memory, 1.000000/1.000000 node:127.0.0.1}\n",
      " In total there are 0 pending tasks and 1 pending actors on this node.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1m42s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n",
      "Exiting!\n",
      "\u001b[2m\u001b[1m\u001b[33m(scheduler +1m50s)\u001b[0m Warning: The following resource request cannot be scheduled right now: {'GPU': 1.0, 'CPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes to this Ray cluster.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import ray\n",
    "from ray.util.metrics import Counter, Gauge, Histogram\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(_metrics_export_port=8080)\n",
    "\n",
    "@ray.remote\n",
    "class MyActor:\n",
    "    def __init__(self, name):\n",
    "        self._curr_count = 0\n",
    "\n",
    "        self.counter = Counter(\n",
    "            \"num_requests\",\n",
    "            description=\"Number of requests processed by the actor.\",\n",
    "            tag_keys=(\"actor_name\", ))\n",
    "        self.counter.set_default_tags({\"actor_name\": name})\n",
    "\n",
    "        self.gauge = Gauge(\n",
    "            \"curr_count\",\n",
    "            description=\"Current count held by the actor. Goes up and down.\",\n",
    "            tag_keys=(\"actor_name\", ))\n",
    "        self.gauge.set_default_tags({\"actor_name\": name})\n",
    "\n",
    "        self.histogram = Histogram(\n",
    "            \"request_latency\",\n",
    "            description=\"Latencies of requests in ms.\",\n",
    "            boundaries=[0.1, 1],\n",
    "            tag_keys=(\"actor_name\", ))\n",
    "        self.histogram.set_default_tags({\"actor_name\": name})\n",
    "\n",
    "    def process_request(self, num):\n",
    "        start = time.time()\n",
    "        self._curr_count += num\n",
    "\n",
    "        # Increment the total request count.\n",
    "        self.counter.inc()\n",
    "        # Update the gauge to the new value.\n",
    "        self.gauge.set(self._curr_count)\n",
    "        # Record the latency for this request in ms.\n",
    "        self.histogram.observe(1000 * (time.time() - start))\n",
    "\n",
    "        return self._curr_count\n",
    "\n",
    "\n",
    "print(\"Starting actor.\")\n",
    "my_actor = MyActor.remote(\"my_actor\")\n",
    "print(\"Calling actor.\")\n",
    "my_actor.process_request.remote(-10)\n",
    "print(\"Calling actor.\")\n",
    "my_actor.process_request.remote(5)\n",
    "print(\"Metrics should be exported.\")\n",
    "print(\"See http://localhost:8080 (this may take a few seconds to load).\")\n",
    "\n",
    "# Sleep so we can look at the metrics before exiting.\n",
    "time.sleep(30)\n",
    "print(\"Exiting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac9827a",
   "metadata": {},
   "source": [
    "Debugger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40309d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:03:31,482\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8266\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def f(x):\n",
    "    breakpoint()\n",
    "    return x * x\n",
    "\n",
    "futures = [f.remote(i) for i in range(2)]\n",
    "print(ray.get(futures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e68e9774",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_8952/1572540588.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\James\\AppData\\Local\\Temp/ipykernel_8952/1572540588.py\"\u001b[1;36m, line \u001b[1;32m23\u001b[0m\n\u001b[1;33m    await def __call__(self, starlette_request):\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "\n",
    "serve.start()\n",
    "\n",
    "# Train model\n",
    "iris_dataset = load_iris()\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(iris_dataset[\"data\"], iris_dataset[\"target\"])\n",
    "\n",
    "# Define Ray Serve model,\n",
    "@serve.deployment(route_prefix=\"/iris\")\n",
    "class BoostingModel:\n",
    "    def __init__(self):\n",
    "        self.model = model\n",
    "        self.label_list = iris_dataset[\"target_names\"].tolist()\n",
    "        \n",
    "    await def __call__(self, starlette_request):\n",
    "        payload = await starlette_request.json()[\"vector\"]\n",
    "        print(f\"Worker: received request with data: {payload}\")\n",
    "\n",
    "        prediction = self.model.predict([payload])[0]\n",
    "        human_name = self.label_list[prediction]\n",
    "        return {\"result\": human_name}\n",
    "\n",
    "# Deploy model\n",
    "serve.start()\n",
    "BoostingModel.deploy()\n",
    "\n",
    "time.sleep(3600.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513b75b",
   "metadata": {},
   "source": [
    "Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3e2e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-05 20:05:40,272\tINFO services.py:1338 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(task\r",
      " pid=6168)\u001b[0m task\r\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "# Initiate a driver.\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "def task():\n",
    "    print(\"task\")\n",
    "\n",
    "ray.get(task.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd9dac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=6168)\u001b[0m INFO:root:A log message for an actor.\n",
      " pid=10148)\u001b[0m INFO:root:A log message for a task\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import logging\n",
    "# Initiate a driver.\n",
    "\n",
    "@ray.remote\n",
    "class Actor:\n",
    "    def __init__(self):\n",
    "        # Basic config automatically configures logs to\n",
    "        # be streamed to stdout and stderr.\n",
    "        # Set the severity to INFO so that info logs are printed to stdout.\n",
    "        logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    def log(self, msg):\n",
    "        logging.info(msg)\n",
    "\n",
    "actor = Actor.remote()\n",
    "ray.get(actor.log.remote(\"A log message for an actor.\"))\n",
    "\n",
    "@ray.remote\n",
    "def f(msg):\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logging.info(msg)\n",
    "\n",
    "ray.get(f.remote(\"A log message for a task\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50271fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(task\r",
      " pid=10148)\u001b[0m task_id: TaskID(4ee449587774c1f0ffffffffffffffffffffffff01000000)\r\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "# Initiate a driver.\n",
    "\n",
    "@ray.remote\n",
    "def task():\n",
    "    print(f\"task_id: {ray.get_runtime_context().task_id}\")\n",
    "\n",
    "ray.get(task.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f2bec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
